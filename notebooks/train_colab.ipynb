{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Stack — Diffusion Policy Training on Colab\n\nTrain the diffusion policy (ResNet18 + ConditionalUnet1D) on real demonstration data.\n\n**Setup:** `Runtime > Change runtime type > T4 GPU` (or A100 with Colab Pro)\n\n**Data:** 17 sessions on Google Drive (BU account), already COLMAP-processed with poses."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify GPU\nimport torch\nassert torch.cuda.is_available(), \"No GPU! Change runtime type.\"\nprint(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repo and install as package\n!git clone https://github.com/corneliusgruss/stack.git /content/stack 2>/dev/null || (cd /content/stack && git pull)\n%cd /content/stack\n!pip install -q -e .\n!pip install -q wandb"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Mount Drive & Link Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\n# Symlink Drive sessions into the repo's data directory\nimport os\nfrom pathlib import Path\n\ndrive_sessions = Path('/content/drive/MyDrive/stack_sessions')\nlocal_data = Path('/content/stack/data/raw')\nlocal_data.mkdir(parents=True, exist_ok=True)\n\n# Unzip any zipped sessions\nimport subprocess\nif drive_sessions.exists():\n    zips = sorted(drive_sessions.glob('*.zip'))\n    for z in zips:\n        session_dir = drive_sessions / z.stem\n        if not session_dir.exists():\n            print(f\"Extracting {z.name}...\")\n            subprocess.run(['unzip', '-q', '-o', str(z), '-d', str(drive_sessions)], check=True)\n\n# Symlink each session into data/raw/\nsessions = sorted([d for d in drive_sessions.iterdir() if d.is_dir() and d.name.startswith('session_')])\nfor s in sessions:\n    link = local_data / s.name\n    if not link.exists():\n        os.symlink(s, link)\n\n# Verify\nimport json\nvalid = 0\nfor s in sorted(local_data.iterdir()):\n    if not s.is_dir() or not s.name.startswith('session_'):\n        continue\n    has_poses = (s / 'poses.json').exists()\n    has_rgb = (s / 'rgb').exists()\n    meta = json.load(open(s / 'metadata.json')) if (s / 'metadata.json').exists() else {}\n    processed = meta.get('slamProcessed', False)\n    n_frames = meta.get('rgbFrameCount', '?')\n    status = 'ready' if (has_poses and has_rgb and processed) else 'MISSING DATA'\n    print(f\"  {s.name}: {n_frames} frames — {status}\")\n    if status == 'ready':\n        valid += 1\n\nprint(f\"\\n{valid} sessions ready for training\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Train"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train on real data\n# ~12M params, 17 sessions, 100 epochs\n# T4: ~15-30 min depending on dataset size\n!python -m stack.scripts.train \\\n    --config configs/default.yaml \\\n    --data-dir data/raw \\\n    --output-dir outputs/real_v1 \\\n    --device cuda \\\n    --wandb"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Evaluate & Download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate best checkpoint\n!python -m stack.scripts.eval \\\n    --checkpoint outputs/real_v1/checkpoint_best.pt \\\n    --data-dir data/raw"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy checkpoint to Drive for persistence\n!cp outputs/real_v1/checkpoint_best.pt /content/drive/MyDrive/stack_sessions/checkpoint_best.pt\n!cp outputs/real_v1/normalizer.pt /content/drive/MyDrive/stack_sessions/normalizer.pt\nprint(\"Checkpoint saved to Drive\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Or download directly\nfrom google.colab import files\nfiles.download('outputs/real_v1/checkpoint_best.pt')"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}