{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# COLMAP Pose Estimation for Stack Sessions\n\nProcess raw capture sessions (ultrawide camera) through COLMAP SfM to get 6DoF poses.\n\n**Requirements:** Google Colab (GPU optional but speeds up feature extraction)\n\n**Pipeline:**\n1. Mount Google Drive, unzip sessions\n2. Subsample frames (60fps → 10fps for better feature matching)\n3. Run COLMAP: feature extraction → sequential matching → SfM\n4. Interpolate poses back to 60fps\n5. Write poses.json back to session"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.environ['QT_QPA_PLATFORM'] = 'offscreen'\n\n!pip install pycolmap -q\n!pip install opencv-python-headless scipy matplotlib -q\n\nimport json\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.transform import Rotation, Slerp\nfrom scipy.interpolate import interp1d\n\ntry:\n    import pycolmap\n    print(f\"pycolmap {pycolmap.__version__} installed\")\nexcept ImportError:\n    print(\"ERROR: pycolmap not installed\")\n\nprint(\"Setup complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive & Select Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\n# Set the path to your session directory on Google Drive\nDRIVE_SESSIONS_DIR = Path('/content/drive/MyDrive/stack_sessions')"
  },
  {
   "cell_type": "code",
   "source": "# Unzip uploaded session archives (skip already-extracted ones)\nimport subprocess\nif DRIVE_SESSIONS_DIR.exists():\n    zips = sorted(DRIVE_SESSIONS_DIR.glob('*.zip'))\n    print(f\"Found {len(zips)} zip files\")\n    for z in zips:\n        session_dir = DRIVE_SESSIONS_DIR / z.stem\n        if session_dir.exists():\n            print(f\"  {z.name}: already extracted, skipping\")\n        else:\n            print(f\"  {z.name}: extracting...\")\n            subprocess.run(['unzip', '-q', '-o', str(z), '-d', str(DRIVE_SESSIONS_DIR)], check=True)\n    print(\"Done!\")\nelse:\n    print(f\"Upload zipped sessions to Google Drive: My Drive/stack_sessions/\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# List available sessions\nif DRIVE_SESSIONS_DIR.exists():\n    sessions = sorted([d for d in DRIVE_SESSIONS_DIR.iterdir() if d.is_dir() and d.name.startswith('session_')])\n    print(f\"Found {len(sessions)} sessions:\")\n    for s in sessions:\n        meta_file = s / 'metadata.json'\n        if meta_file.exists():\n            with open(meta_file) as f:\n                meta = json.load(f)\n            source = meta.get('captureSource', 'iphone_arkit')\n            processed = meta.get('slamProcessed', False)\n            n_frames = meta.get('rgbFrameCount', '?')\n            status = 'done' if processed else ('arkit' if source == 'iphone_arkit' else 'needs SLAM')\n            print(f\"  {s.name}: {n_frames} frames, source={source}, status={status}\")\n        else:\n            print(f\"  {s.name}: no metadata\")\nelse:\n    print(f\"No sessions found at {DRIVE_SESSIONS_DIR}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select session to process\n",
    "SESSION_NAME = 'session_2026-02-20_143000'  # <-- Change this\n",
    "SESSION_DIR = DRIVE_SESSIONS_DIR / SESSION_NAME\n",
    "\n",
    "assert SESSION_DIR.exists(), f\"Session not found: {SESSION_DIR}\"\n",
    "\n",
    "# Load metadata\n",
    "with open(SESSION_DIR / 'metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Subsample Frames & Prepare COLMAP\n\n60fps is too dense for feature matching — subsample to ~10fps, run COLMAP, then interpolate back."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load all frame paths\nrgb_dir = SESSION_DIR / 'rgb'\nall_frame_paths = sorted(rgb_dir.glob('*.jpg'))\nN_total = len(all_frame_paths)\nprint(f\"Total frames: {N_total}\")\n\n# Preview first frame\nfirst_frame = cv2.imread(str(all_frame_paths[0]))\nfirst_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\nH, W = first_frame.shape[:2]\nplt.figure(figsize=(8, 6))\nplt.imshow(first_frame)\nplt.title(f\"Frame 0: {W}x{H}\")\nplt.axis('off')\nplt.show()\n\n# Subsample: every 6th frame (60fps → 10fps)\nSUBSAMPLE = 6\nsub_indices = list(range(0, N_total, SUBSAMPLE))\n# Always include last frame for full coverage\nif sub_indices[-1] != N_total - 1:\n    sub_indices.append(N_total - 1)\nprint(f\"Subsampled: {len(sub_indices)} frames (every {SUBSAMPLE}th)\")\n\n# Copy subsampled frames to local working directory (faster than Drive)\nWORK_DIR = Path('/content/colmap_work')\nWORK_DIR.mkdir(exist_ok=True)\n(WORK_DIR / 'images').mkdir(exist_ok=True)\n(WORK_DIR / 'sparse').mkdir(exist_ok=True)\n\n# Use sequential naming so COLMAP processes them in order\nfor new_idx, orig_idx in enumerate(sub_indices):\n    src = all_frame_paths[orig_idx]\n    dst = WORK_DIR / 'images' / f'{new_idx:06d}.jpg'\n    if not dst.exists():\n        shutil.copy2(src, dst)\n\nprint(f\"Copied {len(sub_indices)} frames to {WORK_DIR / 'images'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Run COLMAP\n\nInstall COLMAP CLI and run: feature extraction → sequential matching → sparse reconstruction."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install COLMAP CLI\n!apt install -y colmap 2>&1 | tail -3\n!colmap -h 2>&1 | head -2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "db_path = WORK_DIR / 'database.db'\nimage_path = WORK_DIR / 'images'\nsparse_path = WORK_DIR / 'sparse'\n\n# Remove old database if re-running\nif db_path.exists():\n    db_path.unlink()\n\n# 1. Feature extraction (CPU SIFT) — single camera, SIMPLE_RADIAL model\n!colmap feature_extractor \\\n    --database_path {db_path} \\\n    --image_path {image_path} \\\n    --ImageReader.camera_model SIMPLE_RADIAL \\\n    --ImageReader.single_camera 1 \\\n    --SiftExtraction.use_gpu 0 \\\n    --SiftExtraction.max_image_size 480 \\\n    --SiftExtraction.max_num_features 4096\n\nprint(\"\\nFeature extraction done\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2. Sequential matching (CPU, exploits video frame ordering)\n!colmap sequential_matcher \\\n    --database_path {db_path} \\\n    --SiftMatching.use_gpu 0 \\\n    --SequentialMatching.overlap 10 \\\n    --SequentialMatching.loop_detection 0\n\nprint(\"\\nSequential matching done\")\n\n# 3. Incremental SfM (mapper) — no GPU needed\nif sparse_path.exists():\n    shutil.rmtree(sparse_path)\nsparse_path.mkdir()\n\n!colmap mapper \\\n    --database_path {db_path} \\\n    --image_path {image_path} \\\n    --output_path {sparse_path} \\\n    --Mapper.init_min_num_inliers 50 \\\n    --Mapper.ba_refine_focal_length 1 \\\n    --Mapper.ba_refine_extra_params 1\n\n# Check reconstruction\nrecon_dirs = sorted(sparse_path.iterdir())\nprint(f\"\\nReconstructions: {len(recon_dirs)}\")\nfor d in recon_dirs:\n    images_file = d / 'images.bin'\n    if images_file.exists():\n        r = pycolmap.Reconstruction(str(d))\n        print(f\"  {d.name}: {r.num_images()} images registered / {len(sub_indices)} total\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Extract Poses & Interpolate to 60fps\n\nCOLMAP gives poses for subsampled frames. Interpolate (Slerp for rotations, linear for translation) to recover poses for all original frames."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load best reconstruction (most registered images)\nbest_recon_dir = max(recon_dirs, key=lambda d: pycolmap.Reconstruction(str(d)).num_images() if (d / 'images.bin').exists() else 0)\nrecon = pycolmap.Reconstruction(str(best_recon_dir))\nprint(f\"Using reconstruction: {best_recon_dir.name} ({recon.num_images()} images)\")\n\n# Extract poses for subsampled frames\nsub_poses = {}  # orig_frame_idx → 4x4 pose matrix\nfor image_id, image in recon.images.items():\n    fname = image.name  # e.g. \"000042.jpg\"\n    sub_idx = int(Path(fname).stem)\n    orig_idx = sub_indices[sub_idx]\n\n    # COLMAP gives cam_from_world (world→camera transform)\n    # We want world_from_cam (camera→world, i.e., camera pose in world frame)\n    cfw = image.cam_from_world()  # Rigid3d\n    R_cw = np.array(cfw.rotation.matrix())\n    t_cw = np.array(cfw.translation)\n\n    # Invert: world_from_cam\n    R_wc = R_cw.T\n    t_wc = -R_wc @ t_cw\n\n    pose = np.eye(4)\n    pose[:3, :3] = R_wc\n    pose[:3, 3] = t_wc\n    sub_poses[orig_idx] = pose\n\nprint(f\"Got poses for {len(sub_poses)} / {len(sub_indices)} subsampled frames\")\n\n# Check coverage\nregistered_indices = sorted(sub_poses.keys())\nprint(f\"Frame range: {registered_indices[0]} to {registered_indices[-1]}\")\n\n# Visualize subsampled trajectory\npositions = np.array([sub_poses[i][:3, 3] for i in registered_indices])\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\nax.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'b.-', linewidth=0.5, markersize=2)\nax.scatter(positions[0, 0], positions[0, 1], positions[0, 2], c='g', s=100, label='Start')\nax.scatter(positions[-1, 0], positions[-1, 1], positions[-1, 2], c='r', s=100, label='End')\nax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\nax.legend()\nax.set_title(f'COLMAP Trajectory ({len(registered_indices)} keyframes)')\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Interpolate poses to all original frames (60fps)\nkey_indices = np.array(registered_indices, dtype=float)\nkey_translations = np.array([sub_poses[i][:3, 3] for i in registered_indices])\nkey_rotations = Rotation.from_matrix([sub_poses[i][:3, :3] for i in registered_indices])\n\n# Target: all frame indices between first and last registered\nfirst_reg, last_reg = registered_indices[0], registered_indices[-1]\nall_indices = np.arange(first_reg, last_reg + 1, dtype=float)\n\n# Interpolate translations (linear)\ninterp_tx = interp1d(key_indices, key_translations[:, 0], kind='linear')\ninterp_ty = interp1d(key_indices, key_translations[:, 1], kind='linear')\ninterp_tz = interp1d(key_indices, key_translations[:, 2], kind='linear')\n\n# Interpolate rotations (Slerp)\nslerp = Slerp(key_indices, key_rotations)\n\n# Build full pose array\nposes_4x4 = np.zeros((N_total, 4, 4), dtype=np.float64)\nposes_valid = np.zeros(N_total, dtype=bool)\n\nfor idx in all_indices:\n    i = int(idx)\n    t = np.array([interp_tx(idx), interp_ty(idx), interp_tz(idx)])\n    R = slerp(idx).as_matrix()\n    poses_4x4[i, :3, :3] = R\n    poses_4x4[i, :3, 3] = t\n    poses_4x4[i, 3, 3] = 1.0\n    poses_valid[i] = True\n\nn_interpolated = poses_valid.sum()\nprint(f\"Interpolated {n_interpolated} poses (frames {first_reg}–{last_reg} of {N_total})\")\nif first_reg > 0 or last_reg < N_total - 1:\n    print(f\"  Note: frames 0–{first_reg-1} and {last_reg+1}–{N_total-1} have no pose (outside COLMAP range)\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 6. Write Poses to Session"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Build poses.json in StackCapture format\nposes_list = []\nfor i in range(N_total):\n    if poses_valid[i]:\n        poses_list.append({\n            'timestamp': float(i) / 60.0,\n            'rgbIndex': i,\n            'depth': None,\n            'transform': poses_4x4[i].tolist(),\n        })\n\n# Write poses.json\nposes_file = SESSION_DIR / 'poses.json'\nwith open(poses_file, 'w') as f:\n    json.dump(poses_list, f, indent=2)\nprint(f\"Wrote {len(poses_list)} poses to {poses_file}\")\n\n# Also save COLMAP intrinsics to calib.txt\nfor cam_id, cam in recon.cameras.items():\n    params = cam.params  # SIMPLE_RADIAL: [f, cx, cy, k]\n    calib_str = f\"{params[0]:.4f} {params[0]:.4f} {params[1]:.4f} {params[2]:.4f}\"\n    calib_file = SESSION_DIR / 'calib.txt'\n    calib_file.write_text(calib_str)\n    print(f\"Wrote intrinsics: {calib_str} (k={params[3]:.4f})\")\n    break\n\n# Update metadata\nmetadata['slamProcessed'] = True\nmetadata['poseCount'] = len(poses_list)\nwith open(SESSION_DIR / 'metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\nprint(f\"Updated metadata: slamProcessed=true\")\n\nprint(f\"\\nSession {SESSION_NAME} ready for training!\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. Batch Process All Sessions"
  },
  {
   "cell_type": "code",
   "source": "# Process all unprocessed sessions\ndef process_session_colmap(session_dir, subsample=6):\n    \"\"\"Run COLMAP SfM on a single session, write poses.json.\"\"\"\n    env = {**os.environ, 'QT_QPA_PLATFORM': 'offscreen'}\n\n    rgb_dir = session_dir / 'rgb'\n    frame_paths = sorted(rgb_dir.glob('*.jpg'))\n    n_total = len(frame_paths)\n\n    # Subsample\n    sub_indices = list(range(0, n_total, subsample))\n    if sub_indices[-1] != n_total - 1:\n        sub_indices.append(n_total - 1)\n\n    # Working directory\n    work = Path('/content/colmap_work')\n    if work.exists():\n        shutil.rmtree(work)\n    work.mkdir()\n    (work / 'images').mkdir()\n    (work / 'sparse').mkdir()\n\n    for new_idx, orig_idx in enumerate(sub_indices):\n        shutil.copy2(frame_paths[orig_idx], work / 'images' / f'{new_idx:06d}.jpg')\n\n    db = work / 'database.db'\n\n    # Feature extraction (CPU)\n    result = subprocess.run([\n        'colmap', 'feature_extractor',\n        '--database_path', str(db),\n        '--image_path', str(work / 'images'),\n        '--ImageReader.camera_model', 'SIMPLE_RADIAL',\n        '--ImageReader.single_camera', '1',\n        '--SiftExtraction.use_gpu', '0',\n        '--SiftExtraction.max_image_size', '480',\n        '--SiftExtraction.max_num_features', '4096',\n    ], capture_output=True, text=True, env=env)\n    if result.returncode != 0:\n        return False, f\"Feature extraction failed: {result.stderr[-200:]}\"\n\n    # Sequential matching (CPU)\n    result = subprocess.run([\n        'colmap', 'sequential_matcher',\n        '--database_path', str(db),\n        '--SiftMatching.use_gpu', '0',\n        '--SequentialMatching.overlap', '10',\n        '--SequentialMatching.loop_detection', '0',\n    ], capture_output=True, text=True, env=env)\n    if result.returncode != 0:\n        return False, f\"Matching failed: {result.stderr[-200:]}\"\n\n    # Mapper\n    result = subprocess.run([\n        'colmap', 'mapper',\n        '--database_path', str(db),\n        '--image_path', str(work / 'images'),\n        '--output_path', str(work / 'sparse'),\n        '--Mapper.init_min_num_inliers', '50',\n        '--Mapper.ba_refine_focal_length', '1',\n        '--Mapper.ba_refine_extra_params', '1',\n    ], capture_output=True, text=True, env=env)\n    if result.returncode != 0:\n        return False, f\"Mapper failed: {result.stderr[-200:]}\"\n\n    # Find best reconstruction\n    recon_dirs = sorted((work / 'sparse').iterdir())\n    if not recon_dirs:\n        return False, \"No reconstruction produced\"\n\n    best_dir = max(recon_dirs, key=lambda d: pycolmap.Reconstruction(str(d)).num_images() if (d / 'images.bin').exists() else 0)\n    recon = pycolmap.Reconstruction(str(best_dir))\n\n    # Extract subsampled poses\n    sub_poses = {}\n    for img_id, img in recon.images.items():\n        sub_idx = int(Path(img.name).stem)\n        orig_idx = sub_indices[sub_idx]\n        cfw = img.cam_from_world()  # Rigid3d\n        R_cw = np.array(cfw.rotation.matrix())\n        t_cw = np.array(cfw.translation)\n        R_wc = R_cw.T\n        t_wc = -R_wc @ t_cw\n        pose = np.eye(4)\n        pose[:3, :3] = R_wc\n        pose[:3, 3] = t_wc\n        sub_poses[orig_idx] = pose\n\n    if len(sub_poses) < 3:\n        return False, f\"Only {len(sub_poses)} images registered\"\n\n    # Interpolate to 60fps\n    reg_indices = sorted(sub_poses.keys())\n    key_idx = np.array(reg_indices, dtype=float)\n    key_t = np.array([sub_poses[i][:3, 3] for i in reg_indices])\n    key_R = Rotation.from_matrix([sub_poses[i][:3, :3] for i in reg_indices])\n\n    first, last = reg_indices[0], reg_indices[-1]\n    all_idx = np.arange(first, last + 1, dtype=float)\n\n    interp_x = interp1d(key_idx, key_t[:, 0])\n    interp_y = interp1d(key_idx, key_t[:, 1])\n    interp_z = interp1d(key_idx, key_t[:, 2])\n    slerp = Slerp(key_idx, key_R)\n\n    poses_list = []\n    for idx in all_idx:\n        i = int(idx)\n        t = np.array([interp_x(idx), interp_y(idx), interp_z(idx)])\n        R = slerp(idx).as_matrix()\n        pose = np.eye(4)\n        pose[:3, :3] = R\n        pose[:3, 3] = t\n        poses_list.append({\n            'timestamp': float(i) / 60.0,\n            'rgbIndex': i,\n            'depth': None,\n            'transform': pose.tolist(),\n        })\n\n    # Write poses.json\n    with open(session_dir / 'poses.json', 'w') as f:\n        json.dump(poses_list, f, indent=2)\n\n    # Write calib.txt\n    for cam_id, cam in recon.cameras.items():\n        p = cam.params\n        (session_dir / 'calib.txt').write_text(f\"{p[0]:.4f} {p[0]:.4f} {p[1]:.4f} {p[2]:.4f}\")\n        break\n\n    # Update metadata\n    with open(session_dir / 'metadata.json') as f:\n        meta = json.load(f)\n    meta['slamProcessed'] = True\n    meta['poseCount'] = len(poses_list)\n    with open(session_dir / 'metadata.json', 'w') as f:\n        json.dump(meta, f, indent=2)\n\n    return True, f\"{recon.num_images()}/{len(sub_indices)} keyframes → {len(poses_list)} poses\"\n\n\n# Process all sessions\nsessions = sorted([d for d in DRIVE_SESSIONS_DIR.iterdir() if d.is_dir() and d.name.startswith('session_')])\nfor s in sessions:\n    meta_file = s / 'metadata.json'\n    if not meta_file.exists():\n        continue\n    with open(meta_file) as f:\n        meta = json.load(f)\n    if meta.get('slamProcessed', False):\n        print(f\"  {s.name}: already processed, skipping\")\n        continue\n    if meta.get('captureSource') == 'iphone_arkit':\n        print(f\"  {s.name}: ARKit session, skipping\")\n        continue\n\n    print(f\"  {s.name}: processing...\", end=' ')\n    ok, msg = process_session_colmap(s)\n    status = 'OK' if ok else 'FAILED'\n    print(f\"{status} — {msg}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}